# Add Output-First Response Style for Faster Time-to-Value

## Summary

This PR addresses issue #4030 by implementing an `output_first` response style that instructs agents to prioritize delivering answers over conversational filler.

**Key Changes:**
- Added `response_style` field to `GraphSpec` with two options: `output_first` (default) and `conversational`
- The `output_first` style is now the default, promoting faster time-to-value for users
- Updated prompt composition to include response style guidance in the system prompt
- Simplified node prompts in the `deep_research_agent` template to leverage the output-first style

## Problem

Users reported that agents often respond with multi-line conversational framing and clarification questions before delivering the actual answer. This delays value for users who already have clear intent.

Examples:
- "I'd be happy to help with that!"
- "Good question! Let me think..."
- Asking clarifying questions when the prompt is not actually ambiguous

## Solution

Added a `response_style` configuration option that controls how agents structure their responses:

### `output_first` (default)
```
1. LEAD WITH THE ANSWER. When the user's request is clear, provide the output/result first.
2. BE CONCISE. No introductions, no "good question" filler, no restating the obvious.
3. CLARIFY ONLY WHEN AMBIGUOUS. If the request is genuinely unclear, ask 1-2 focused questions.
   Do not ask clarifying questions when a reasonable interpretation exists.
4. CONTEXT AFTER OUTPUT. Add explanation, alternatives, or follow-up suggestions after the main answer.
5. NO CONVERSATIONAL FILLER. Skip "I'd be happy to help" or "Let me think about that."
```

### `conversational`
Traditional style for use cases that benefit from a warmer tone.

## Files Changed

- `core/framework/graph/edge.py` - Add `response_style` field to `GraphSpec`
- `core/framework/graph/prompt_composer.py` - Add `RESPONSE_STYLES` dict and `build_response_style_prompt()` function
- `core/framework/graph/executor.py` - Pass `response_style` to `compose_system_prompt()`
- `core/framework/runtime/execution_stream.py` - Include `response_style` in graph cloning
- `core/tests/test_continuous_conversation.py` - Add tests for response style functionality
- `examples/templates/deep_research_agent/agent.py` - Use `output_first` style
- `examples/templates/deep_research_agent/nodes/__init__.py` - Simplify prompts for output-first style
- `.claude/skills/hive-create/examples/deep_research_agent/nodes/__init__.py` - Updated template

## Testing

Added comprehensive tests for the response style feature:
- Test that `output_first` style contains expected guidance
- Test that `conversational` style contains expected guidance
- Test that unknown styles default to `output_first`
- Test that `compose_system_prompt()` includes response style by default
- Test that `RESPONSE_STYLES` dict has required keys

## Backwards Compatibility

- Default behavior is now `output_first` (more direct responses)
- To restore previous conversational behavior, set `response_style="conversational"` in GraphSpec
- Existing agents continue to work, but will now use the output-first style by default

Resolves #4030
