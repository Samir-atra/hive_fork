## Summary

- Fixed `hive_coder/config.py` to use `get_max_tokens()` instead of hardcoded `40000`
- Updated `file_templates.md` to use `framework.config.RuntimeConfig` pattern

## Problem

The `hive_coder` agent had `max_tokens=40000` hardcoded, which exceeds OpenAI model limits:
- OpenAI GPT-4o: 16384 max completion tokens
- This caused `OpenAIException: max_tokens is too large: 40000` runtime failures

## Solution

Changed `hive_coder/config.py` to use the centralized configuration functions:
- `get_max_tokens()` → returns `DEFAULT_MAX_TOKENS` (8192)
- `get_preferred_model()` → loads model from `~/.hive/configuration.json`
- `get_api_key()` → handles API key resolution
- `get_api_base()` → handles custom API base URLs

This aligns `hive_coder` with all other agent templates (deep_research_agent, tech_news_reporter, etc.) which already use `framework.config.RuntimeConfig`.

## Files Changed

- `core/framework/agents/hive_coder/config.py` - Use centralized config functions
- `core/framework/agents/hive_coder/reference/file_templates.md` - Update template to use RuntimeConfig

## Testing

The change was verified by:
1. Confirming `DEFAULT_MAX_TOKENS = 8192` in `framework/graph/edge.py`
2. Ensuring the new config follows the same pattern as other agent templates

Resolves #3988
